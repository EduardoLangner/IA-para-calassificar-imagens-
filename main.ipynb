{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neurais Convolucionais (CNNs ou ConvNets) são um tipo de arquitetura de rede neural profunda projetada especialmente para tarefas de processamento de imagens. Elas são inspiradas no funcionamento do sistema visual biológico dos animais e são amplamente utilizadas em visão computacional e tarefas de reconhecimento de padrões em imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # manipular array multidimencionais\n",
    "import matplotlib.pyplot as plt # criar graficos e plotar resultados\n",
    "from keras.datasets import mnist, cifar10 # conjuntos de dados populares para classificar imagens, são usadas para testar redes neurais convolucionais\n",
    "\n",
    "from keras.models import Sequential\n",
    "#é uma pilha linear de camadas que você pode adicionar para construir sua rede neural.\n",
    "\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "# Dense: Esta camada é uma camada totalmente conectada, comumente usada na parte final de redes neurais para classificação.\n",
    "#Flatten: Esta camada é usada para transformar dados de entrada multidimensionais em uma forma unidimensional, comumente antes de camadas densas.\n",
    "#Conv2D: Esta é uma camada de convolução 2D usada para extrair características de imagens.\n",
    "#MaxPooling2D: Essa camada é usada para realizar o agrupamento máximo 2D, reduzindo a resolução espacial dos dados.\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "# codificação one-hot de rótulos categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18743 images belonging to 2 classes.\n",
      "Found 18743 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Epoch 1/10\n",
      "  3/586 [..............................] - ETA: 2:55:05 - loss: 1.0944 - acc: 0.4688"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import VGG16, InceptionV3, ResNet50, DenseNet121\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "#é uma pilha linear de camadas que você pode adicionar para construir sua rede neural.\n",
    "\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "# Defina o diretório raiz do seu conjunto de dados\n",
    "train_dir = \"C:\\\\Users\\\\cosmo\\\\Desktop\\\\ClassificadorDeImagens\\\\train\"\n",
    "test_dir = \"C:\\\\Users\\\\cosmo\\\\Desktop\\\\ClassificadorDeImagens\\\\test\"\n",
    "\n",
    "# Crie um gerador de dados de imagem usando o flow_from_directory\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)  # Normaliza os valores dos pixels\n",
    "\n",
    "# Carregue as imagens do diretório usando o flow_from_directory\n",
    "image_size = (224, 224)  # Defina o tamanho desejado para as imagens\n",
    "batch_size = 32  # Tamanho do lote\n",
    "class_mode = 'binary'  # Modo de classificação\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode,\n",
    "    # color_mode='grayscale',  # Define o modo de cor para escala de cinza\n",
    ")\n",
    "\n",
    "# Verifique as classes disponíveis\n",
    "class_names = list(generator.class_indices.keys())\n",
    "\n",
    "# Visualize uma imagem do lote\n",
    "images, labels = generator.next()\n",
    "train_data, tmp_data, train_labels, tmp_labels = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "test_data, val_data, test_labels, val_labels = train_test_split(tmp_data, tmp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Definindo o gerador de dados\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(train_dir,\n",
    "                                              target_size=(224, 224),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(test_dir,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='binary')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(test_dir,\n",
    "                                             target_size=(224, 224),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='binary',\n",
    "                                             shuffle=False)\n",
    "\n",
    "# Definindo a função para criar modelos\n",
    "def create_model(base_model):\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Criando modelos com base nas arquiteturas pré-treinadas\n",
    "vgg16_model = create_model(VGG16(weights='imagenet',\n",
    "                                 include_top=False,\n",
    "                                 input_shape=(224, 224, 3)))\n",
    "\n",
    "inception_model = create_model(InceptionV3(weights='imagenet',\n",
    "                                           include_top=False,\n",
    "                                           input_shape=(224, 224, 3)))\n",
    "\n",
    "resnet_model = create_model(ResNet50(weights='imagenet',\n",
    "                                     include_top=False,\n",
    "                                     input_shape=(224, 224, 3)))\n",
    "\n",
    "densenet_model = create_model(DenseNet121(weights='imagenet',\n",
    "                                          include_top=False,\n",
    "                                          input_shape=(224, 224, 3)))\n",
    "\n",
    "# Função para compilar e treinar o modelo\n",
    "def compile_and_train(model, train_generator, validation_generator, epochs=10):\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['acc'])\n",
    "    history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
    "    return model, history\n",
    "\n",
    "# Treinando os modelos\n",
    "vgg16_model, vgg16_history = compile_and_train(vgg16_model, train_generator, validation_generator)\n",
    "inception_model, inception_history = compile_and_train(inception_model, train_generator, validation_generator)\n",
    "resnet_model, resnet_history = compile_and_train(resnet_model, train_generator, validation_generator)\n",
    "densenet_model, densenet_history = compile_and_train(densenet_model, train_generator, validation_generator)\n",
    "\n",
    "# Função para avaliar o modelo\n",
    "def evaluate_model(model, test_generator):\n",
    "    test_generator.reset()\n",
    "    predictions = model.predict(test_generator)\n",
    "    y_pred = np.round(predictions).astype(int)\n",
    "    y_true = test_generator.classes\n",
    "    report = classification_report(y_true, y_pred, target_names=['Normal', 'Covid-19'])\n",
    "    print(report)\n",
    "\n",
    "# Avaliando os modelos\n",
    "print(\"VGG16:\")\n",
    "evaluate_model(vgg16_model, test_data)\n",
    "print(\"InceptionV3:\")\n",
    "evaluate_model(inception_model, test_data)\n",
    "print(\"ResNet50:\")\n",
    "evaluate_model(resnet_model, test_data)\n",
    "print(\"DenseNet121:\")\n",
    "evaluate_model(densenet_model, test_data)\n",
    "\n",
    "\n",
    "# Crie uma figura e um eixo\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plote a primeira imagem do lote (agora em escala de cinza)\n",
    "ax.imshow(np.squeeze(images[0]), cmap='gray')\n",
    "ax.set_title(class_names[np.argmax(labels[0])])\n",
    "\n",
    "# Exiba a imagem plotada\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
