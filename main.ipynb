{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neurais Convolucionais (CNNs ou ConvNets) são um tipo de arquitetura de rede neural profunda projetada especialmente para tarefas de processamento de imagens. Elas são inspiradas no funcionamento do sistema visual biológico dos animais e são amplamente utilizadas em visão computacional e tarefas de reconhecimento de padrões em imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # manipular array multidimencionais\n",
    "import matplotlib.pyplot as plt # criar graficos e plotar resultados\n",
    "from keras.datasets import mnist, cifar10 # conjuntos de dados populares para classificar imagens, são usadas para testar redes neurais convolucionais\n",
    "\n",
    "from keras.models import Sequential\n",
    "#é uma pilha linear de camadas que você pode adicionar para construir sua rede neural.\n",
    "\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "# Dense: Esta camada é uma camada totalmente conectada, comumente usada na parte final de redes neurais para classificação.\n",
    "#Flatten: Esta camada é usada para transformar dados de entrada multidimensionais em uma forma unidimensional, comumente antes de camadas densas.\n",
    "#Conv2D: Esta é uma camada de convolução 2D usada para extrair características de imagens.\n",
    "#MaxPooling2D: Essa camada é usada para realizar o agrupamento máximo 2D, reduzindo a resolução espacial dos dados.\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "# codificação one-hot de rótulos categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18743 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cosmo\\Desktop\\ClassificadorDeImagens\\main.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cosmo/Desktop/ClassificadorDeImagens/main.ipynb#W2sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model, history\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cosmo/Desktop/ClassificadorDeImagens/main.ipynb#W2sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m# Treinando os modelos\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cosmo/Desktop/ClassificadorDeImagens/main.ipynb#W2sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m vgg16_model, vgg16_history \u001b[39m=\u001b[39m compile_and_train(vgg16_model, train_data, val_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cosmo/Desktop/ClassificadorDeImagens/main.ipynb#W2sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m inception_model, inception_history \u001b[39m=\u001b[39m compile_and_train(inception_model, train_data, val_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cosmo/Desktop/ClassificadorDeImagens/main.ipynb#W2sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m resnet_model, resnet_history \u001b[39m=\u001b[39m compile_and_train(resnet_model, train_data, val_data)\n",
      "\u001b[1;32mc:\\Users\\cosmo\\Desktop\\ClassificadorDeImagens\\main.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cosmo/Desktop/ClassificadorDeImagens/main.ipynb#W2sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile_and_train\u001b[39m(model, train_generator, validation_generator, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cosmo/Desktop/ClassificadorDeImagens/main.ipynb#W2sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cosmo/Desktop/ClassificadorDeImagens/main.ipynb#W2sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(train_generator, epochs\u001b[39m=\u001b[39mepochs, validation_data\u001b[39m=\u001b[39mvalidation_generator)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cosmo/Desktop/ClassificadorDeImagens/main.ipynb#W2sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[1;32mc:\\Users\\cosmo\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\cosmo\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1703\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[39mif\u001b[39;00m validation_split \u001b[39mand\u001b[39;00m validation_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1693\u001b[0m     \u001b[39m# Create the validation data using the training data. Only supported\u001b[39;00m\n\u001b[0;32m   1694\u001b[0m     \u001b[39m# for `Tensor` and `NumPy` input.\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     (\n\u001b[0;32m   1696\u001b[0m         x,\n\u001b[0;32m   1697\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1700\u001b[0m         (x, y, sample_weight), validation_split\u001b[39m=\u001b[39mvalidation_split\n\u001b[0;32m   1701\u001b[0m     )\n\u001b[1;32m-> 1703\u001b[0m \u001b[39mif\u001b[39;00m validation_data:\n\u001b[0;32m   1704\u001b[0m     (\n\u001b[0;32m   1705\u001b[0m         val_x,\n\u001b[0;32m   1706\u001b[0m         val_y,\n\u001b[0;32m   1707\u001b[0m         val_sample_weight,\n\u001b[0;32m   1708\u001b[0m     ) \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39munpack_x_y_sample_weight(validation_data)\n\u001b[0;32m   1710\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39m_should_use_with_coordinator:\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import VGG16, InceptionV3, ResNet50, DenseNet121\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "#é uma pilha linear de camadas que você pode adicionar para construir sua rede neural.\n",
    "\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "# Defina o diretório raiz do seu conjunto de dados\n",
    "data_directory = \"C:\\\\Users\\\\cosmo\\\\Desktop\\\\ClassificadorDeImagens\\\\train\"\n",
    "\n",
    "# Crie um gerador de dados de imagem usando o flow_from_directory\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)  # Normaliza os valores dos pixels\n",
    "\n",
    "# Carregue as imagens do diretório usando o flow_from_directory\n",
    "image_size = (224, 224)  # Defina o tamanho desejado para as imagens\n",
    "batch_size = 32  # Tamanho do lote\n",
    "class_mode = 'binary'  # Modo de classificação\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode,\n",
    "    # color_mode='grayscale',  # Define o modo de cor para escala de cinza\n",
    ")\n",
    "\n",
    "\n",
    "# Verifique as classes disponíveis\n",
    "class_names = list(generator.class_indices.keys())\n",
    "\n",
    "# Visualize uma imagem do lote\n",
    "images, labels = generator.next()\n",
    "train_data, tmp_data, train_labels, tmp_labels = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "test_data, val_data, test_labels, val_labels = train_test_split(tmp_data, tmp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Definindo o gerador de dados\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(train_dir,\n",
    "                                              target_size=(224, 224),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(validation_dir,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='binary')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(test_dir,\n",
    "                                             target_size=(224, 224),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='binary',\n",
    "                                             shuffle=False)\n",
    "\n",
    "# Definindo a função para criar modelos\n",
    "def create_model(base_model):\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Criando modelos com base nas arquiteturas pré-treinadas\n",
    "vgg16_model = create_model(VGG16(weights='imagenet',\n",
    "                                 include_top=False,\n",
    "                                 input_shape=(224, 224, 3)))\n",
    "\n",
    "inception_model = create_model(InceptionV3(weights='imagenet',\n",
    "                                           include_top=False,\n",
    "                                           input_shape=(224, 224, 3)))\n",
    "\n",
    "resnet_model = create_model(ResNet50(weights='imagenet',\n",
    "                                     include_top=False,\n",
    "                                     input_shape=(224, 224, 3)))\n",
    "\n",
    "densenet_model = create_model(DenseNet121(weights='imagenet',\n",
    "                                          include_top=False,\n",
    "                                          input_shape=(224, 224, 3)))\n",
    "\n",
    "# Função para compilar e treinar o modelo\n",
    "def compile_and_train(model, train_generator, validation_generator, epochs=10):\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['acc'])\n",
    "    history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
    "    return model, history\n",
    "\n",
    "# Treinando os modelos\n",
    "vgg16_model, vgg16_history = compile_and_train(vgg16_model, train_data, val_data)\n",
    "inception_model, inception_history = compile_and_train(inception_model, train_data, val_data)\n",
    "resnet_model, resnet_history = compile_and_train(resnet_model, train_data, val_data)\n",
    "densenet_model, densenet_history = compile_and_train(densenet_model, train_data, val_data)\n",
    "\n",
    "# Função para avaliar o modelo\n",
    "def evaluate_model(model, test_generator):\n",
    "    test_generator.reset()\n",
    "    predictions = model.predict(test_generator)\n",
    "    y_pred = np.round(predictions).astype(int)\n",
    "    y_true = test_generator.classes\n",
    "    report = classification_report(y_true, y_pred, target_names=['Normal', 'Covid-19'])\n",
    "    print(report)\n",
    "\n",
    "# Avaliando os modelos\n",
    "print(\"VGG16:\")\n",
    "evaluate_model(vgg16_model, test_data)\n",
    "print(\"InceptionV3:\")\n",
    "evaluate_model(inception_model, test_data)\n",
    "print(\"ResNet50:\")\n",
    "evaluate_model(resnet_model, test_data)\n",
    "print(\"DenseNet121:\")\n",
    "evaluate_model(densenet_model, test_data)\n",
    "\n",
    "\n",
    "# Crie uma figura e um eixo\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plote a primeira imagem do lote (agora em escala de cinza)\n",
    "ax.imshow(np.squeeze(images[0]), cmap='gray')\n",
    "ax.set_title(class_names[np.argmax(labels[0])])\n",
    "\n",
    "# Exiba a imagem plotada\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
